{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "494df12b",
   "metadata": {},
   "source": [
    "# From Bloqade Squin kernels to Stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cd5e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from kirin import ir\n",
    "from bloqade.stim.emit import EmitStimMain\n",
    "from bloqade.stim.passes import SquinToStimPass\n",
    "\n",
    "# circuit emitter\n",
    "def codegen(mt: ir.Method):\n",
    "    # method should not have any arguments!\n",
    "    buf = io.StringIO()\n",
    "    emit = EmitStimMain(dialects=bloqade_stim.main, io=buf)\n",
    "    emit.initialize()\n",
    "    emit.run(mt)\n",
    "    return buf.getvalue().strip()\n",
    "\n",
    "# language compiler and converter\n",
    "def to_stim(mt: ir.Method):\n",
    "    SquinToStimPass(mt.dialects)(mt)\n",
    "    return codegen(mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39db3772",
   "metadata": {},
   "source": [
    "# Squin gates of interest\n",
    "\n",
    "given immutable lists `q: IList[Qubit, Literal[7]]` of qubits, and `p: float` noise rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6796d831",
   "metadata": {},
   "source": [
    "### Depolarizing noise channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ec582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bloqade import squin as sq\n",
    "\n",
    "# Single qubit noise; broadcast applies channel in parallel to all qubits in list \n",
    "sq.broadcast.depolarize(p, [q[0], q[1]])\n",
    "\n",
    "# Two-qubit noise; broadcast applies channel in parallel to all qubits in lists \n",
    "sq.broadcast.depolarize2(p, q1, q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfc67da",
   "metadata": {},
   "source": [
    "### Measure and reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036b0c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure\n",
    "sq.broadcast.measure(q)\n",
    "\n",
    "# reset\n",
    "sq.broadcast.reset(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7184bb",
   "metadata": {},
   "source": [
    "note that to implement resets and measurements on single qubits, just drop `.broadcast` and apply to single-qubit registers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d7e448",
   "metadata": {},
   "source": [
    "### Convert circuit to Stim/Tsim, visualize, run sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39349a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stim\n",
    "import tsim\n",
    "\n",
    "# conversion pipeline\n",
    "@squin.kernel\n",
    "def main():\n",
    "    my_kernel()\n",
    "\n",
    "stim_code = to_stim(main)\n",
    "stim_circ = tsim.Circuit(stim_code)\n",
    "\n",
    "# plotting circuit diagram (Tsim has better functionality for that)\n",
    "stim_circ.diagram(height=400)\n",
    "\n",
    "# sampling using Stim\n",
    "sampler = stim_circ.compile_sampler()\n",
    "samples = sampler.sample(shots=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a873ff",
   "metadata": {},
   "source": [
    "### Using and adjusting heuristic noise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling mask for correlated CZ error rates of heuristic noise model\n",
    "def make_scaled_cz_correlated_rates(s: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Scale the default correlated CZ error rates by factor `s`.\n",
    "    \n",
    "    The II (identity-identity) entry represents \"no error\", all other entries\n",
    "    are error probabilities. We scale the errors and adjust II to maintain normalization.\n",
    "    \"\"\"\n",
    "    # Default rates from the noise model\n",
    "    default_rates = np.array([\n",
    "        [9.93492628e-01, 2.27472300e-04, 2.27472300e-04, 1.51277730e-03],\n",
    "        [2.27472300e-04, 1.42864200e-04, 1.42864200e-04, 1.43082900e-04],\n",
    "        [2.27472300e-04, 1.42864200e-04, 1.42864200e-04, 1.43082900e-04],\n",
    "        [1.51277730e-03, 1.43082900e-04, 1.43082900e-04, 1.42813990e-03],\n",
    "    ])\n",
    "    \n",
    "    # Scale all error entries\n",
    "    scaled_rates = default_rates.copy()\n",
    "    scaled_rates[0, 0] = 0  # temporarily zero out II\n",
    "    scaled_rates = scaled_rates * s  # scale all errors\n",
    "    \n",
    "    # Recalculate II to maintain normalization (sum = 1)\n",
    "    scaled_total_error = scaled_rates.sum()\n",
    "    scaled_rates[0, 0] = 1.0 - scaled_total_error\n",
    "    \n",
    "    # Clamp to valid probability range\n",
    "    if scaled_rates[0, 0] < 0:\n",
    "        raise ValueError(f\"Scaling factor {s} too large - total error probability exceeds 1.0\")\n",
    "    \n",
    "    return scaled_rates\n",
    "def make_error_model(s: float = 1.0) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Create a dictionary of error-model parameters scaled by factor `s`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s : float\n",
    "        Global scaling factor applied multiplicatively to all nonzero\n",
    "        error probabilities.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, float]\n",
    "        Dictionary of scaled error-model parameters.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        # Local errors\n",
    "        \"local_px\": 0.0004102 * s,\n",
    "        \"local_py\": 0.0004102 * s,\n",
    "        \"local_pz\": 0.0004112 * s,\n",
    "        \"local_loss_prob\": 0.0,\n",
    "\n",
    "        \"local_unaddressed_px\": 2e-7 * s,\n",
    "        \"local_unaddressed_py\": 2e-7 * s,\n",
    "        \"local_unaddressed_pz\": 1.2e-6 * s,\n",
    "        \"local_unaddressed_loss_prob\": 0.0,\n",
    "\n",
    "        # Global errors\n",
    "        \"global_px\": 0.000065 * s,\n",
    "        \"global_py\": 0.000065 * s,\n",
    "        \"global_pz\": 0.000065 * s,\n",
    "        \"global_loss_prob\": 0.0,\n",
    "\n",
    "        # CZ gates\n",
    "        \"cz_paired_gate_px\": 0.0006549 * s,\n",
    "        \"cz_paired_gate_py\": 0.0006549 * s,\n",
    "        \"cz_paired_gate_pz\": 0.003184 * s,\n",
    "        \"cz_gate_loss_prob\": 0.0,\n",
    "\n",
    "        \"cz_unpaired_gate_px\": 0.0005149 * s,\n",
    "        \"cz_unpaired_gate_py\": 0.0005149 * s,\n",
    "        \"cz_unpaired_gate_pz\": 0.002185 * s,\n",
    "        \"cz_unpaired_loss_prob\": 0.0,\n",
    "\n",
    "        # Motion-related\n",
    "        \"mover_px\": 0.000806 * s,\n",
    "        \"mover_py\": 0.000806 * s,\n",
    "        \"mover_pz\": 0.002458 * s,\n",
    "        \"move_loss_prob\": 0.0,\n",
    "\n",
    "        \"sitter_px\": 0.0003066 * s,\n",
    "        \"sitter_py\": 0.0003066 * s,\n",
    "        \"sitter_pz\": 0.0004639 * s,\n",
    "        \"sit_loss_prob\": 0.0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eb926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bloqade.cirq_utils import noise\n",
    "from bloqade.cirq_utils.emit import emit_circuit\n",
    "from bloqade.cirq_utils import load_circuit\n",
    "\n",
    "# applying noise model to circuit according to different architectures; must use Cirq circuit\n",
    "@squin.kernel\n",
    "def main():\n",
    "    my_kernel()\n",
    "\n",
    "cirq_main = emit_circuit(main) # emit to Cirq\n",
    "noise_model = noise.GeminiOneZoneNoiseModel() # define noise model; here OneZone default\n",
    "main_noisy = noise.transform_circuit(cirq_main, model=noise_model) # annotate circuit w noise\n",
    "squin_main = load_circuit(main_noisy) #back to Squin\n",
    "noisy_stim = to_stim(squin_main) #now to Stim\n",
    "\n",
    "\n",
    "# Example: defining new noise model on top of OneZone architecture\n",
    "noise_scale = 1\n",
    "noise_model = noise.GeminiOneZoneNoiseModel(cz_paired_correlated_rates= make_scaled_cz_correlated_rates(noise_scale), **make_error_model(noise_scale))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87da5b9",
   "metadata": {},
   "source": [
    "Notice that Tsim may perform better than Stim as a backend sampler when using the automatized heuristic noise models, given rounding errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2026-planning-QuEra-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
